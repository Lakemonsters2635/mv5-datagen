{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Data Generation for YOLOv7+ with VOCDataset and Training of YOLOv11\n",
    "1. Take pictures\n",
    "1. Prepare object images\n",
    "1. Prepare environment\n",
    "1. Organize the object images\n",
    "1. Download VOCDataset for backing of object images\n",
    "1. Overlay objects on backing images and generate YOLO labels\n",
    "1. Train model\n",
    "1. Upload to [tools.luxonis.com](https://tools.luxonis.com) to convert to OpenVINO format\n",
    "1. Export to Raspberry Pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take Pictures\n",
    "When taking the images of the object for training make sure to take them with conditions and angles similar to what the robot will see in competition. Also make sure that the image also has nothing important in it besides the object. \n",
    "\n",
    "Good examples: *ADD IMAGES*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Object Images\n",
    "Once you have your images head over to [remove.bg](https://remove.bg) and upload each image. Then open up each image without a background to GIMP or your photo editor of choice and crop the images until you are right at the edge of them down to the pixel.\n",
    "\n",
    "Good example: *ADD IMAGES*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clone the ultralytics github which contains yolov11 and create other folders that we will need later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\ultralytics'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone --progress --verbose https://github.com/ultralytics/ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir objectImages\n",
    "!mkdir ultralytics\\Dataset\\images\\test\n",
    "!mkdir ultralytics\\Dataset\\images\\train\n",
    "!mkdir ultralytics\\Dataset\\labels\\test\n",
    "!mkdir ultralytics\\Dataset\\labels\\train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install dependencies for yolov11 and all other ultralytics yolo versions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics tqdm>=4.41.0 pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organize Object Images\n",
    "Currently the file structure of important files should look like:\n",
    "```\n",
    "ultralytics\n",
    "├── ultralytics\n",
    "|     ├── Dataset\n",
    "|     |     ├── images\n",
    "|     |     └── labels\n",
    "|     └── (folders with all of the yolo code and other things we will get to later)  \n",
    "├── objectImages\n",
    "└── (more yolo files and folders)\n",
    "```\n",
    "\n",
    "Rename all of the images to `*class*_*number*`<br>\n",
    "ex: `blue_1`, `cone_29`, `banana_0`\n",
    "\n",
    "Take all of the images you just edited and put them in the folder named `objectImages`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now edit the list below to contain all of your class names. We will need this later for generating the dataset and training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classNames = [\"blueBalloon\", \"redBalloon\"] # Edit\n",
    "import os\n",
    "CLASSES = {key: index for index, key in enumerate(classNames)} # DON'T EDIT\n",
    "os.environ['CLASSES'] = str(CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download VOCDataset for Backing of Object Images\n",
    "We use the VOCDataset or Visualized Object Classes Dataset which is a dataset that contains many images with labels for training of pascal. We are just extracting the images from a few of the datasets for backing images for our yolo training images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the 2007 and 2012 VOCDataset and put them in a separate directory (may take 10+ minutes depending on wifi):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir VOCdevkit\n",
    "!wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar -O ./VOCdevkit/VOCtrainval_06-Nov-2007.tar\n",
    "!wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar -O ./VOCdevkit/VOCtest_06-Nov-2007.tar\n",
    "!wget http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar -O ./VOCdevkit/VOCtrainval_11-May-2012.tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the downloaded .tar archive files (should create folders `VOC2007` and `VOC2012` in `VOCdevkit`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xvf ./VOCdevkit/VOCtrainval_06-Nov-2007.tar\n",
    "!tar -xvf ./VOCdevkit/VOCtest_06-Nov-2007.tar\n",
    "!tar -xvf ./VOCdevkit/VOCtrainval_11-May-2012.tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we convert VOC dataset to YOLO-format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from tqdm import tqdm as progressBar\n",
    "import os\n",
    "import shutil\n",
    "import argparse\n",
    "\n",
    "# VOC dataset (refer https://github.com/meituan/YOLOv6/blob/main/yolov6/data/voc2yolo.py)\n",
    "# VOC2007 trainval: 446MB, 5012 images\n",
    "# VOC2007 test:     438MB, 4953 images\n",
    "# VOC2012 trainval: 1.95GB, 17126 images\n",
    "\n",
    "DATASET_YEARS = ('2012', 'train'), ('2012', 'val'), ('2007', 'train'), ('2007', 'val'), ('2007', 'test')\n",
    "\n",
    "def voc2yolo(voc_path):\n",
    "    for year, image_set in DATASET_YEARS:\n",
    "        imgs_path = os.path.join(voc_path, 'images', f'{image_set}') # ./VOCdevkit/images/train\n",
    "        print(\"Searching for image in:\", imgs_path)\n",
    "\n",
    "        # Sepperate images into train, test, val based on whether or not the number is in the text file\n",
    "        # Makes it work with multiple files\n",
    "        try:\n",
    "            with open(os.path.join(voc_path, f'VOC{year}/ImageSets/Main/{image_set}.txt'), 'r') as f: # ./VOCdevkit/VOC2007/ImageSets/Main/train.txt\n",
    "                image_ids = f.read().strip().split() # removes extra spaces from the lines and splits them along the \"/n\"\n",
    "            if not os.path.exists(imgs_path): # Create the image path that we needed earlier\n",
    "                os.makedirs(imgs_path)\n",
    "                print(f'Creating {imgs_path}')\n",
    "\n",
    "            # for each image ID it copies it into either the test, train, val folders\n",
    "            for id in progressBar(image_ids, desc=f'{image_set}{year}'):\n",
    "                f = os.path.join(voc_path, f'VOC{year}/JPEGImages/{id}.jpg')  # old img path\n",
    "                if os.path.exists(f):\n",
    "                    shutil.move(f, imgs_path)       # move image to new image path\n",
    "        except Exception as e:\n",
    "            print(f'[Warning]: {e} {year} {image_set} convert fail!')\n",
    "\n",
    "    reorganizeImagePaths(voc_path)\n",
    "\n",
    "def reorganizeImagePaths(voc_path):\n",
    "    '''\n",
    "    Generate backing dataset structure:\n",
    "    train: # train images 16551 images\n",
    "        - images/train\n",
    "        - images/val\n",
    "    val: # val images (relative to 'path')  4952 images\n",
    "        - images/test\n",
    "    '''\n",
    "    dataset_root = os.path.join(voc_path, 'backingImages')\n",
    "    print('='*20)\n",
    "    print(f'dataset_root: {dataset_root}')\n",
    "    if not os.path.exists(dataset_root):\n",
    "        os.makedirs(dataset_root)\n",
    "        print('Creating')\n",
    "    \n",
    "    file_structure = {'train': ['train', 'val'], 'test':['test']}\n",
    "    for data_type, data_list in file_structure.items():\n",
    "        for data_name in data_list:\n",
    "            ori_path = os.path.join(voc_path, \"images\", data_name)\n",
    "            new_path = os.path.join(dataset_root, data_type)\n",
    "            if not os.path.exists(new_path):\n",
    "                os.makedirs(new_path)\n",
    "\n",
    "            print(f'[INFO]: Moving {ori_path} to {new_path}')\n",
    "            for file in progressBar(os.listdir(ori_path)):\n",
    "                shutil.move(os.path.join(ori_path, file), new_path)\n",
    "    if os.path.exists(os.path.join(voc_path, \"images\")):\n",
    "        shutil.rmtree(os.path.join(voc_path, \"images\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we run the code we just wrote on the directory of the VOC images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc2yolo('./VOCdevkit/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlay objects on backing images and generate YOLO labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./dataGen.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./dataGen.py\n",
    "from PIL import Image\n",
    "import random\n",
    "import os\n",
    "from tqdm import tqdm as progressBar\n",
    "import threading\n",
    "import multiprocessing\n",
    "import concurrent.futures\n",
    "import argparse\n",
    "\n",
    "classNames = [\"blueBalloon\", \"redBalloon\"] # Edit\n",
    "CLASSES = {key: index for index, key in enumerate(classNames)} # DON'T EDIT\n",
    "\n",
    "# prompt: write a function using PIL to take a first PNG image with a transparent background, scale it down a certain percentage and paste it on a second PNG image and return the result.\n",
    "def stackAndScaleImage(objectImage, backgroundImage, scalePercent, position):\n",
    "  \"\"\"\n",
    "  Takes a first PNG image, scales it down a certain percentage and pastes it on a second PNG image.\n",
    "\n",
    "  Args:\n",
    "  objectImage: PIL image of object\n",
    "  backgroundImage: PIL image of background\n",
    "  scalePercent: Percentage to scale down the first image. (MAKE FLOAT INSTEAD OF DUMB STUFF)\n",
    "  position: Tuple of (x, y) coordinates to paste the scaled image.\n",
    " \n",
    "  Returns:\n",
    "  A PIL Image object with the first image pasted on the second image.\n",
    "  \"\"\"\n",
    "\n",
    "  objectImage = Image.open(objectImage)\n",
    "  backgroundImage = Image.open(backgroundImage)\n",
    "\n",
    "  # Scale down the first image\n",
    "  width, height = objectImage.size                     # extract the width and height of object\n",
    "  newWidth = int(width * scalePercent)            # create a new width for object based on the scalePercent and makes it an int\n",
    "  newHeight = int(height * scalePercent)          # create a new height for object based on the scalePercent and makes it an int\n",
    "  objectScaled = objectImage.resize((newWidth, newHeight)) # use the resize method of a PIL Image to scale object to the new_width and new_height\n",
    " \n",
    "  #==== Scaled the hight to add more variation to the data\n",
    "  width, height = objectScaled.size # Reset the width and height variables to be the new width and height of object after scaling\n",
    "  randomHeightScale = random.uniform(0.8, 1.2) # Choose a random scalePercent between the minimum and maximum values.\n",
    "  newHeight = int(height * randomHeightScale) # Calculate the newHeight based on the random scalePercent above\n",
    "  if newHeight > backgroundImage.height:\n",
    "    newHeight = backgroundImage.height\n",
    "  objectScaled = objectScaled.resize((width, newHeight)) # Resize the image just like above\n",
    "  #====\n",
    "\n",
    "  backgroundImage.paste(objectScaled, position, objectScaled) # Paste the scaled image (object_scaled) on the second image without scaling the second image. (second parameter makes it so that the pixels with no value meant to be clear stay clear and aren't black)\n",
    "\n",
    "  return backgroundImage # Return the final stacked image\n",
    "\n",
    "# prompt: write a function called combine_images which uses the stack_scaled_images function defined above and scale object to a random value between some minimum percentage and some maximum percentage of the size of background.  The position for object to be pasted onto background is randomly selected within the bounds of background\n",
    "# SCALE PERCENTAGE IS HOW MUH OF THE FRAME YOU WANT TO TAKE UP NOT HOW MUCH YOU WANT TO SCALE THE OBJECT IMAGE DOWN\n",
    "def selectScaleAndCreateYoloLabels(objectPath, backgroundPath, minSizePercent, maxSizePercent, objectClassStr):\n",
    "  \"\"\"\n",
    "  Combines two images by pasting a scaled version of an object onto a background.\n",
    "\n",
    "  SCALES BASED ON WIDTH\n",
    "\n",
    "  Args:\n",
    "    objectPath: Path to the object image.\n",
    "    backgroundPath: Path to the background image.\n",
    "    minSizePercent: Minimum percentage to scale down object's WIDTH.\n",
    "    maxSizePercent: Maximum percentage to scale down object's WIDTH.\n",
    "\n",
    "  Returns:\n",
    "    A PIL Image object with the combined images.\n",
    "  \"\"\"\n",
    "\n",
    "  object = Image.open(objectPath) # Open the first image as object\n",
    "  background = Image.open(backgroundPath) # Open the second image as background\n",
    "\n",
    "  objectWidth, objectHeight = object.size # Extract the width and height of object as objectWidth and objectHeight\n",
    "  backgroundWidth, backgroundHeight = background.size # Extract the width and height of background as backgroundWidth and backgroundHeight\n",
    "\n",
    "  # Choose a random scalePercent between the minimum and maximum values provided as parameters\n",
    "  # NEVER ABOVE 1.0(?)\n",
    "  scalePercent = random.uniform(minSizePercent, maxSizePercent)\n",
    "\n",
    "  # as background's width before applying this random scale percent (should really be same as shortest side?)\n",
    "  # baseScale = backgroundWidth / objectWidth # The baseScale is the ratio of how big background's width is compared to object's width (ONLY WITH MEASUREMENTS)\n",
    "  baseScale = backgroundWidth/objectWidth if backgroundWidth <= backgroundHeight else backgroundHeight/objectHeight # scale based on shortest side of background\n",
    "  \"\"\"\n",
    "  print({\n",
    "    \"backgroundWidth\": backgroundWidth,\n",
    "    \"object.width\": object.width,\n",
    "    \"objectWidth\": objectWidth,\n",
    "    \"baseScale\": baseScale,\n",
    "    \"scalePercent\": scalePercent,\n",
    "    \"baseScale * scalePercent\": baseScale * scalePercent,\n",
    "    \"object.width * scalePercent/100\": object.width * scalePercent/100,\n",
    "    \"object.height * scalePercent/100\": object.height * scalePercent/100,\n",
    "  })\n",
    "  \"\"\"\n",
    "\n",
    "  scalePercent = baseScale * scalePercent # fix the scalePercent to include the baseScale between the 2 images and be proportional\n",
    "\n",
    "  # Choose a random position for object in background\n",
    "  widthOfObjectAfterScaling = int(object.width * scalePercent)   # predict width of object after scaling so you can choose a random width in bounds of background\n",
    "  heightOfObjectAfterScaling = int(object.height * scalePercent) # predict height of object after scaling so you can choose a random height in bounds of background\n",
    "  x = random.randint(0, backgroundWidth - widthOfObjectAfterScaling)     # select random x position for object in background\n",
    "\n",
    "  # ERROR IS HERE: The error is because background isn't tall enough to fit object even after scaling so the randint is trying to selced from 0 to a negative number\n",
    "  y = random.randint(0, backgroundHeight - heightOfObjectAfterScaling)   # select random y position for object in background\n",
    "\n",
    "  combinedImage = stackAndScaleImage(objectPath, backgroundPath, scalePercent, (x, y)) # Use the stack_scaled_images function to combine the two images\n",
    "\n",
    "  # Save the paste_parameters as a json object\n",
    "  debugParameters = {\n",
    "    \"width_background\": backgroundWidth,\n",
    "    \"height_background\": backgroundHeight,\n",
    "    \"paste_x\": x,\n",
    "    \"paste_y\": y,\n",
    "    \"paste_width\": widthOfObjectAfterScaling,\n",
    "    \"paste_height\": heightOfObjectAfterScaling,\n",
    "  }\n",
    "\n",
    "  # https://docs.cogniflow.ai/en/article/how-to-create-a-dataset-for-object-detection-using-the-yolo-labeling-format-1tahk19/\n",
    "  # YOLO labeling parameters\n",
    "  pasteParametersYolo = {\n",
    "    \"objectClassNum\": CLASSES[objectClassStr],\n",
    "    \"x_center\": (x + widthOfObjectAfterScaling/2.0) / backgroundWidth, # calculate what percentage of the width of background the center of scaled object will be\n",
    "    \"y_center\": (y + heightOfObjectAfterScaling/2.0) / backgroundHeight, # calculate what percentage of the height of background the center of scaled object will be\n",
    "    \"width\": widthOfObjectAfterScaling / backgroundWidth, # calculate what percentage of the width of background does scaled object take\n",
    "    \"height\": heightOfObjectAfterScaling / backgroundHeight, # calculate what percentage of the height of background does scaled object take\n",
    "  }\n",
    "\n",
    "  return (combinedImage, debugParameters, pasteParametersYolo) # return the PIL image object after stacking, the parameters used for pasting, and the parameters used for pasting in a YOLO suitable notation\n",
    "\n",
    "\n",
    "# prompt: write a function which uses the combine_images_james function defined above to randomly select an object from directory1 and combine it from a random background from directory2\n",
    "def combineRandomImages(directory1, directory2, minSizePercent, maxSizePercent):\n",
    "  \"\"\"\n",
    "  Combines two random images from the two directories using the combine_images_james function.\n",
    "\n",
    "  Args:\n",
    "    directory1: Path to the first directory.\n",
    "    directory2: Path to the second directory.\n",
    "    minSizePercent: Minimum percentage to scale down the first image.\n",
    "    maxSizePercent: Maximum percentage to scale down the first image.\n",
    "\n",
    "  Returns:\n",
    "    A PIL Image object with the combined images.\n",
    "  \"\"\"\n",
    "\n",
    "  # Get all files in directories. If one isn't an image it could break\n",
    "  objectFiles = os.listdir(directory1) # Get a list of all files in the first directory\n",
    "  backgroundFiles = os.listdir(directory2) # Get a list of all files in the second directory\n",
    "\n",
    "  imageChosen = random.choice(objectFiles)\n",
    "  objectClass = imageChosen.split(\"_\")[0]\n",
    "\n",
    "  # Choose random images\n",
    "  objectPath = os.path.join(directory1, imageChosen) # Choose a random file from the first directory\n",
    "  backgroundPath = os.path.join(directory2, random.choice(backgroundFiles)) # Choose a random file from the second directory\n",
    "\n",
    "  # Use the combine_images_james_xy function to combine the two images.\n",
    "  combinedImage, debugParameters, pasteParametersYolo = selectScaleAndCreateYoloLabels(objectPath, backgroundPath, minSizePercent, maxSizePercent, objectClass)\n",
    "\n",
    "  # print(pasteParametersYolo)\n",
    "\n",
    "  return (combinedImage, debugParameters, pasteParametersYolo) # re-return all of the returns from the combine_images_james_xy function\n",
    "\n",
    "# def makeImage(testOrTrain=\"test\", numImages=10, minSizePercent=.05, maxSizePercent=.8, i=-1):\n",
    "def makeImage(args):\n",
    "  (testOrTrain, numImages, minSizePercent, maxSizePercent, i) = args\n",
    "  if i == -1:\n",
    "    raise ValueError(\"Invalid i Value\")\n",
    "  # Combine the images from directory1 (game object) with images from directory2 (backgrounds).\n",
    "  combinedImage, debugParameters, pasteParametersYolo = combineRandomImages(\"./objectImages\", \"./VOCdevkit/backingImages/\"+testOrTrain, minSizePercent, maxSizePercent)\n",
    "  # Figure out a file name based on the current iteration and type of dataset\n",
    "  baseFilename = f\"{testOrTrain}_{i:0{6}d}\" # Max 100000 file names\n",
    "  # Save the image to the specified folder based on type of data set and use the above created filename\n",
    "  combinedImage.save('./ultralytics/Dataset/images/'+testOrTrain+'/'+baseFilename+'.png')\n",
    "\n",
    "  # Open/create a text file with the same name as the image and add the paste_parameters_yolo to it\n",
    "  with open('./ultralytics/Dataset/labels/'+testOrTrain+'/'+baseFilename+'.txt', \"w\") as f:\n",
    "    yoloData = pasteParametersYolo\n",
    "    f.write(f\"{yoloData['objectClassNum']} {round(yoloData['x_center'],6)} {round(yoloData['y_center'],6)} {round(yoloData['width'],6)} {round(yoloData['height'],6)}\") # write data and round it to the correct decimal places (first digit in string is the class)\n",
    "\n",
    "\n",
    "# Main function that ties together all of the other functions to make it work\n",
    "# def makeData(testOrTrain=\"test\", numImages=10, minSizePercent=.05, maxSizePercent=.8):\n",
    "if __name__ == \"__main__\":\n",
    "  parser = argparse.ArgumentParser()\n",
    "  parser.add_argument(\"classes\", nargs='?', type=dict)\n",
    "  parser.add_argument(\"testOrTrain\", nargs=1, default=\"test\", type=str)\n",
    "  parser.add_argument(\"numImages\", nargs=1, default=2, type=int)\n",
    "  parser.add_argument(\"minSizePercent\", nargs=1, default=.05, type=float)\n",
    "  parser.add_argument(\"maxSizePercent\", nargs=1, default=.8, type=float)\n",
    "\n",
    "  inputArgs = parser.parse_args()\n",
    "  CLASSES = inputArgs.classes\n",
    "  testOrTrain = inputArgs.testOrTrain\n",
    "  numImages = inputArgs.numImages\n",
    "  minSizePercent = inputArgs.minSizePercent\n",
    "  maxSizePercent = inputArgs.maxSizePercent\n",
    "\n",
    "  testOrTrain = testOrTrain.lower()\n",
    "\n",
    "  args = tuple([(testOrTrain, numImages, minSizePercent, maxSizePercent, i) for i in range(numImages)]) # creates a tuple of tuple\n",
    "  \n",
    "  with multiprocessing.Pool() as p:\n",
    "    print(p.map(makeImage, args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: dataGen.py [-h]\n",
      "                  [classes] testOrTrain numImages minSizePercent\n",
      "                  maxSizePercent\n",
      "dataGen.py: error: argument classes: invalid dict value: \"classes={'blueBalloon':\"\n"
     ]
    }
   ],
   "source": [
    "!python dataGen.py classes=$CLASSES testOrTrain=\"test\" numImages=100 minPercentSize=.5 maxPercentSize=.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\ultralytics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LakeM\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'d:\\\\ultralytics'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd /ultralytics/\n",
    "import os\n",
    "os.getcwd()\n",
    "# os.listdir(\"../ultralytics/objectImages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file objectImages already exists.\n"
     ]
    }
   ],
   "source": [
    "!mkdir objectImages\n",
    "!mkdir ultralytics\\Dataset\\images\\test\n",
    "!mkdir ultralytics\\Dataset\\images\\train\n",
    "!mkdir ultralytics\\Dataset\\labels\\test\n",
    "!mkdir ultralytics\\Dataset\\labels\\train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('test', 1, 0.05, 0.8, 0),)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "import sys\n",
    "makeData('test', 1)\n",
    "# with open('error_log.txt', 'w') as f:\n",
    "    # original_stderr = sys.stderr\n",
    "    # sys.stderr = f\n",
    "# cProfile.run(\"makeData('test', 52)\", \"profileData.pstats\")\n",
    "# p = pstats.Stats('profileData.pstats')\n",
    "# p.sort_stats('calls').print_stats()\n",
    "    # sys.stderr = original_stderr\n",
    "# makeData(\"train\", 20000, .05, .4) # Change this number to change the number of training images that will be created\n",
    "# makeData(\"test\", 5000, .05, .4) # Change this number to change the number of test/val images that will be created"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
